{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "from fastai import Flatten\n",
    "import torchvision.models as models\n",
    "import tqdm\n",
    "import torch.optim as optim\n",
    "import sys\n",
    "stdout = sys.stdout\n",
    "from sklearn.metrics import hamming_loss, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import label_ranking_loss, coverage_error, label_ranking_average_precision_score\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        for i in ['car', 'aeroplane', 'pottedplant', 'tvmonitor', 'cat', 'bus', 'bird', 'cow', 'dog',\\\n",
    "                'sofa', 'sheep', 'chair', 'bottle', 'person', 'bicycle', 'boat', 'motorbike', 'horse',\\\n",
    "                'diningtable', 'train']:\n",
    "            df[i] = df[i].map({1:1, 0:1, -1:0})\n",
    "        self.img_path = df.img_path\n",
    "        self.labels = df.values[:,-2048-20:-2048].astype(np.int16)\n",
    "        self.preprocess = T.Compose([\n",
    "            T.Resize(size=(224, 224)),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_path.iloc[index]).convert('RGB')\n",
    "        img = self.preprocess(img)\n",
    "        return img, self.labels[index]\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    def preprocess(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(x):\n",
    "    return 1./(1+np.exp(-x))\n",
    "def evaluate(y, y_, pivot=0.5):\n",
    "    true_labels = y\n",
    "    predict_probs = sigmoid(y_)\n",
    "    predict_labels = (predict_probs>pivot).astype(np.int)\n",
    "    #print(\"-----------------example based metrics--------------------------\")\n",
    "    #hammingLoss = hamming_loss(true_labels, predict_labels)\n",
    "    accuracy = jaccard_similarity_score(true_labels, predict_labels)\n",
    "    #subset_accuracy = accuracy_score(true_labels, predict_labels)\n",
    "    #precision = precision_score(true_labels, predict_labels, average=\"samples\")\n",
    "    #recall = recall_score(true_labels, predict_labels, average=\"samples\")\n",
    "    f1Score = f1_score(true_labels, predict_labels, average=\"samples\")\n",
    "\n",
    "    # label based metrics\n",
    "    #print(\"------------------label based metrics---------------------------\")\n",
    "    #micro_precision = precision_score(true_labels, predict_labels, average=\"micro\")\n",
    "    #micro_recall = recall_score(true_labels, predict_labels, average=\"micro\")\n",
    "    micro_F1_score = f1_score(true_labels, predict_labels, average=\"micro\")\n",
    "    #macro_precision = precision_score(true_labels, predict_labels, average=\"macro\")\n",
    "    #macro_recall = recall_score(true_labels, predict_labels, average=\"macro\")\n",
    "    macro_F1_score = f1_score(true_labels, predict_labels, average=\"macro\")\n",
    "\n",
    "    # rank metrics\n",
    "    #print(\"--------------------rank metrics--------------------------------\")\n",
    "    #ranking_loss = label_ranking_loss(true_labels, predict_probs)\n",
    "    #one_error = None\n",
    "    #coverage = coverage_error(true_labels, predict_probs)\n",
    "    MAP = average_precision_score(y_true=true_labels, y_score=predict_probs, average='macro')\n",
    "    return accuracy, f1Score, micro_F1_score, macro_F1_score, MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from fastai.callback import SmoothenValue\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc = nn.Sequential(*[\n",
    "            nn.Linear(20, 1)\n",
    "        ])\n",
    "    def forward(self, h):\n",
    "        return self.fc(h)\n",
    "\n",
    "class MyGAN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyGAN, self).__init__()\n",
    "        self.predictor = models.resnet18(pretrained=True)\n",
    "        self.predictor.fc = nn.Linear(512, 20)\n",
    "        self.discriminator = Discriminator()\n",
    "    def forward(self, x, y):\n",
    "        y_ = self.predictor(x)\n",
    "        false_logit = self.discriminator((y_>0).float())\n",
    "        true_logit = self.discriminator(y)\n",
    "        return y_, false_logit, true_logit\n",
    "class MyLoss(nn.Module):\n",
    "    def __init__(self, alpha):\n",
    "        super(MyLoss, self).__init__()\n",
    "        self.loss1 = nn.BCEWithLogitsLoss() # for expression\n",
    "        self.loss2 = nn.BCEWithLogitsLoss() # for discriminator\n",
    "        self.alpha = alpha\n",
    "    def forward(self, y_, y, false_logit):\n",
    "        l1 = self.loss1(input=y_, target=y)\n",
    "        l2 = self.loss2(input=false_logit, target=torch.ones_like(false_logit))\n",
    "        return (1-self.alpha)*l1 + self.alpha*l2\n",
    "class MyDiscriminatorLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyDiscriminatorLoss, self).__init__()\n",
    "        self.loss1 = nn.BCEWithLogitsLoss()\n",
    "    def forward(self, false_logit, true_logit):\n",
    "        l1 = self.loss1(input=false_logit, target=torch.zeros_like(false_logit)) + \\\n",
    "            self.loss1(input=true_logit, target=torch.ones_like(true_logit))\n",
    "        return l1/2\n",
    "    \n",
    "from sklearn.metrics import classification\n",
    "def train_one_epoch(dl, net, loss_fn=None, optimizer=None, train_flag=True):\n",
    "    loss = SmoothenValue(beta=0.9)\n",
    "    if train_flag is True:\n",
    "        g_loss, d_loss = loss_fn\n",
    "        g_optimizer, d_optimizer = optimizer\n",
    "    #pbar = tqdm.tqdm_notebook(dl, leave=False)\n",
    "    y, y_ = [], []\n",
    "    for batch in dl:\n",
    "        batch_x, batch_y = batch[0].float().cuda(), batch[1].float().cuda()\n",
    "        batch_y_, batch_false_logit, batch_true_logit = net(batch_x, batch_y)\n",
    "        \n",
    "        if train_flag is True:\n",
    "            batch_g_loss = g_loss(batch_y_, batch_y, batch_false_logit)\n",
    "            g_optimizer.zero_grad(); batch_g_loss.backward(retain_graph=True); g_optimizer.step()\n",
    "            batch_d_loss = d_loss(batch_false_logit, batch_true_logit)\n",
    "            d_optimizer.zero_grad(); batch_d_loss.backward(); d_optimizer.step()\n",
    "            loss.add_value(batch_g_loss.item())\n",
    "            #pbar.set_description(desc=\"loss:%.4f\" % loss.smooth)\n",
    "        y.append(batch_y.cpu().numpy())\n",
    "        y_.append(batch_y_.detach().cpu().numpy())\n",
    "    y = np.concatenate(y, axis=0)\n",
    "    y_ = np.concatenate(y_, axis=0)\n",
    "    return y, y_, loss.mov_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, trn_dl, test_dl, net, loss_fn=None, optimizer=None):\n",
    "    metric = {'loss':[], 'acc':[], 'f1':[], 'micf1':[], 'macf1':[], 'ap':[]}\n",
    "    for i in range(epochs):\n",
    "        y1, y1_, trn_loss = train_one_epoch(trn_dl, net, loss_fn, optimizer)\n",
    "        trn_acc, trn_f1, trn_mic_f1, trn_mac_f1, trn_map = evaluate(y1, y1_, pivot=0.5)\n",
    "        y1, y1_, test_loss = train_one_epoch(test_dl, net, train_flag=False)\n",
    "        test_acc, test_f1, test_mic_f1, test_mac_f1, test_map = evaluate(y1, y1_, pivot=0.5)\n",
    "        stdout.write(\"%d\\t\" % i)\n",
    "        stdout.write(\"train: %.4f, %.4f, %.4f, %.4f, %.4f, %.4f\\t\" % (trn_loss, trn_acc, trn_f1, trn_mic_f1, trn_mac_f1, trn_map))\n",
    "        stdout.write(\"test : %.4f, %.4f, %.4f, %.4f, %.4f, %.4f\\n\" % (test_loss, test_acc, test_f1, test_mic_f1, test_mac_f1, test_map))\n",
    "        metric['loss'].append(test_loss)\n",
    "        metric['acc'].append(test_acc)\n",
    "        metric['f1'].append(test_f1)\n",
    "        metric['micf1'].append(test_mic_f1)\n",
    "        metric['macf1'].append(test_mac_f1)\n",
    "        metric['ap'].append(test_map)\n",
    "    return metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_path = '/sdadata/zzq/dataset/MultiLabel/VOC2007/feature_ds_trainval.csv'\n",
    "trainval_df = pd.read_csv(trainval_path, index_col=0)\n",
    "test_path = '/sdadata/zzq/dataset/MultiLabel/VOC2007/feature_ds_test.csv'\n",
    "test_df = pd.read_csv(test_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MyDataset(trainval_df)\n",
    "test_ds = MyDataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=32, num_workers=4, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=32, num_workers=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paramtune(alpha, epochs=10):\n",
    "    my_net = MyGAN().cuda()\n",
    "    d_optimizer = optim.Adam(params=my_net.discriminator.parameters(), lr=1e-3)\n",
    "    g_optimizer = optim.Adam(params=my_net.predictor.parameters(), lr=1e-3)\n",
    "    d_loss = MyDiscriminatorLoss().cuda()\n",
    "    g_loss = MyLoss(alpha).cuda()\n",
    "    res = train(epochs, train_dl, test_dl, my_net, loss_fn=[g_loss, d_loss], optimizer=[g_optimizer, d_optimizer])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_set = [0.0, 0.0001,0.001,0.01,0.1,0.2,0.3, 0.4, 0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "times = 1\n",
    "for alpha in tqdm.tqdm_notebook(alpha_set):\n",
    "    res = {'loss':[], 'acc':[], 'f1':[], 'micf1':[], 'macf1':[], 'ap':[]}\n",
    "    for i in range(times):\n",
    "        tmp = paramtune(alpha)\n",
    "        res['loss'].append(np.array(tmp['loss']).min())\n",
    "        res['acc'].append(np.array(tmp['acc']).max())\n",
    "        res['f1'].append(np.array(tmp['f1']).max())\n",
    "        res['micf1'].append(np.array(tmp['micf1']).max())\n",
    "        res['macf1'].append(np.array(tmp['macf1']).max())\n",
    "        res['ap'].append(np.array(tmp['ap']).max())\n",
    "    stdout.write(\"alpha:%.5f  \" % alpha)\n",
    "    stdout.write(\"mean-->\")\n",
    "    #stdout.write(\"loss:%.4f, \" % np.array(res['loss']).mean())\n",
    "    stdout.write(\"acc:%.4f, \" % np.array(res['acc']).mean())\n",
    "    stdout.write(\"micro-f1:%.4f, \" % np.array(res['micf1']).mean())\n",
    "    stdout.write(\"macro-f1:%.4f, \" % np.array(res['macf1']).mean())\n",
    "    stdout.write(\"map:%.4f \\t\" % np.array(res['ap']).mean())\n",
    "    \n",
    "    stdout.write(\"std-->\")\n",
    "    #stdout.write(\"loss:%.4f, \" % np.array(res['loss']).std())\n",
    "    stdout.write(\"acc:%.4f, \" % np.array(res['acc']).std())\n",
    "    stdout.write(\"micro-f1:%.4f, \" % np.array(res['micf1']).std())\n",
    "    stdout.write(\"macro-f1:%.4f, \" % np.array(res['macf1']).std())\n",
    "    stdout.write(\"map:%.4f\\n\" % np.array(res['ap']).std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
